RCNN
첫번째 논문

딥러닝을 이용한 이미지 디테션의 시초
처음으로, 효과적으로 풀었다


(낙타를 탄 사람)
일반전에적으로 

이미지안에서 피처를 CNN으로 뽑아낸다.
물체를 네모를 쳐줘야한다.

디테션 이미지안에 네모를 치고 여기에 어떤것이 있다.
이미지안에서 딥러닝 학습이 아닌, 기존의 방법으로 네모를 뽑는다.
원하는 사이즈로 리사이즈 -> 정사각형화 -> CNN 집어넣고 -> 피처를 뽑는다

네모를 2000개 뽑고 각각 CNN집어넣고 분류
찾고싶은거 분류의 갯수 +1 쓸모없는 박스를 담는것


3개의 컴포넌트
1.물체가 있을거 같은 공간에 네모 (오래 걸린다)

2.네모로부터 CNN를 통과시킨다.

3.입력이미지를 가지고 피처를 뽑는다
입력된 이미지에 상관없이 정사각형으로 만든다



내가 찾고 싶은 


GPU 한장에 13초, CPU 한장에 53초

오래 걸리는 이유 -> 이미지에 2천개 뽑고 각각 CNN에 들어가서 오래걸린다.


이걸 해결하기 위해\

REGION PROPOSAL 를 통해 2000개 뽑기
뽑힌 네모가 실제 네모와 얼마나 겹치는지 확인
겹치는 영역이 IoU0.5보다 크면 POSITIVE 데이터


얼마나 겹치는지만 알고, 내가 실제 바운딩 박스와 어떻게 하면 가까워 질 수 있는지?
 = Bounding box regression
4개의 숫자  중심점, 종횜비 얼마나 바뀌는지, 






SPPnet
앞에서 큰거 뒤에서 작은거 구분
하나의 이미지를넓이가 반이되게 자른다

내가 찾고싶은 사이즈의 

이미지스케일에 

장점 - RCNN 의 단점 보안. 느린거 -> CNN이 한번

픽스된 인풋 사이즈 필요 -> 이미지에서 바운딩 뽑는건 
전체 이미지를 CNN 를 통해 먼저 뽑고 

서로다른 이미지 리사이즈해서  = RCNN

fixed-length representation 찾기


